---
title: "Introduction to locality sensitive hashing"
author: Andee Kaplan
institute: |
    | Duke University
    | Department of Statistical Science
    | andrea.kaplan@duke.edu
shortinstitute: andrea.kaplan@duke.edu
date: |
  | February 8, 2018
  |
  | Slides available at <http://bit.ly/cimat-lsh>
  |
output: 
  beamer_presentation:
    keep_tex: false
    template: beamer.tex
fig_caption: true
classoption: compress
natbib: true
---

```{r libraries, echo=FALSE, message=FALSE, warning=FALSE}
library(knitr)
library(ggplot2)
library(RecordLinkage)

opts_chunk$set(echo=FALSE, message=FALSE, warning=FALSE)
```

# Goal and outline

**Goal: ** Introduce locality sensitive hashing, a fast method of blocking for record linkage, and get some experience doing LSH in `R`.

\vfill
1. Defining similarity
\vfill
1. Representing data as sets (shingling)
\vfill
1. Hashing
\vfill
1. Hashing with compression (minhashing)
\vfill
1. Too many pairs to compare! (LSH)
\vfill
1. Evaluation
\vfill

# Finding similar items

- We want to find similar items
\vfill
    - Maybe we are looking for near duplicate documents (plagiarism)
    \vfill
    - More likely, we are trying to block our data which we can later pass to a record linkage process
    \vfill
- How do we define *similar*?
\vfill

# Jaccard similarity

There are many ways to define similarity, we will use *Jaccard similarity* for this task.
$$
Jac(S, T) = \frac{\mid S \cap T\mid}{\mid S \cup T \mid}
$$

 
\begin{figure}[h]
\centering
\includegraphics[width=.5\textwidth]{images/jaccard}
\caption{Two sets S and T with Jaccard similarity 3/7. The two sets share 3 elements in common, and there are 7 elements in total.}
\label{fig:jaccard}
\end{figure}

# How to represent data as sets

We want to talk about similarity of data $\Rightarrow$ we need sets to compare!

- One way is to construct from the data the set of **short strings** that appear within it
\vfill
- Similar documents/datasets will have many common elements, i.e. many commong short strings
\vfill
- We can do construct these short strings using *shingling*
\vfill

# $k$-shingling (how-to)

1. Think of a document or record as a string of characters
\vfill
2. A $k$-shingle (k-gram) is any sub-string (word) of length $k$ found within the document or record
\vfill
3. Associate with each document or record the set of $k$-shingles that appear one or more times within it
\vfill

# Let's try

Suppose our document is the string "Hello world" and $k  = 2$, then 

- the set of $2$-shingles is $\{\text{he, el, ll, lo, ow, wo, or, rl, ld}\}$
\vfill
- the set of $3$-shingles is $\{\text{hel, ell, llo, low, owo, wor, orl, rld}\}$
\vfill

# Your turn

We have the following two records:

```{r your-turn1}
data("RLdata500")
records <- RLdata500[129:130, c(1,3)]
names(records) <- c("First name", "Last name")
kable(records)
```

1. Compute the $2$-shingles for each record
\vfill
2. Using Jaccard similarity, how similar are they?
\vfill

# Your turn solution
\vfill
1. The $2$-shingles for the first record are $\{\text{mi, ic, ch, ha, ae, el, lv, vo, og, ge, el}\}$ and for the second are $\{\text{mi, ic, ch, ha, ae, el, lm, me, ey, ye, er}\}$.
\vfill
2. There are 6 items in common $\{\text{mi, ic, ch, ha, ae, el}\}$ and 16 items total $\{\text{mi, ic, ch, ha, ae, el, lv, vo, og, ge, el, lm, me, ey, ye, er}\}$, so the Jaccard similarity is $\frac{6}{16} = \frac{3}{8} = `r round(3/8, 4)`$
\vfill

# Useful packages/functions in `R`

(Obviously) We don't want to do this by hand most times. Here are some useful packages in `R` that can help us!

```{r helpful-packages, echo = TRUE}
# detecting text reuse and document similarity + shingles
library(textreuse) 
library(tokenizers)
```

We can use the following functions to create $k$-shingles and calculate Jaccard similarity for our data

```{r helpful-functions, eval=FALSE, echo=TRUE}
# get k-shingles
tokenize_character_shingles(x, n)

# calculate jaccard similarity for two sets
jaccard_similarity(a, b) 
```

# Example data

Research paper headers and citations, with information on authors, title, institutions, venue, date, page numbers and several other fields.

\tiny
```{r load-ex-data, echo=TRUE}
library(RLdata)
data(cora)
str(cora)
```

# Your turn 

Using the `title`, `authors`, and `journal` fields in the `cora` dataset,

\vfill
1. Get the $3$-shingles for each record (**hint:** use `tokenize_character_shingles`).
\vfill
2. Obtain the Jaccard similarity between each pair of records (**hint:** use `jaccard_similarity`).
\vfill

# Your turn solution

```{r your-turn2-sol, echo=TRUE, cache=TRUE}
# get only the columns we want
dat <- cora[, c("title", "authors", "journal")]

# 1. paste the columns together and tokenize for each record
shingles <- apply(dat, 1, function(x) {
  tokenize_character_shingles(paste(x, collapse=" "), n = 3)
})

# 2. Jaccard similarity between pairs
jaccard <- expand.grid(record1 = seq_len(nrow(dat)),
                       record2 = seq_len(nrow(dat)))

# don't need to compare the same things twice
jaccard <- jaccard[jaccard$record1 < jaccard$record2,]

time <- Sys.time()
jaccard$similarity <- apply(jaccard, 1, function(pair) {
  jaccard_similarity(shingles[[pair[1]]], shingles[[pair[2]]])
})
time <- difftime(Sys.time(), time, units = "secs")
```
This took took $r round(time, 2)$ seconds $\approx r round(time/(60), 2)$ minutes!

# Your turn solution (cont'd)

```{r your-turn2-plot}
ggplot(jaccard) +
  geom_raster(aes(x = record1, y = record2, fill=similarity)) +
  theme(aspect.ratio = 1)
```

# Hashing

For a dataset of size $n$, the number of comparisons we must compute is $\frac{n(n-1)}{2}$. 

- For our set of records, we needed to compute $`r nrow(dat)*(nrow(dat) - 1)/2`$ comparisons
\vfill
- A better approach for datasets of any realistic size is to use *hashing*
\vfill

# Similarity preserving summaries of sets

# Characteristic matrix

# Minhashing

# LSH (avoid pairwise comparisons)

# Banding and buckets

# Your turn 

banding in R

# Putting it all together

Choosing shingle size - somewhere?

# "Easy" LSH in R

# Evaluation

# Your turn

perform LSH and evaluate how we did


